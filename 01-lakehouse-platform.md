# üèùÔ∏è 1. Databricks Lakehouse Platform

## 1.1 Rela√ß√£o entre Data Lakehouse e Data Warehouse

```
+-------------------+         +-------------------+
|   Data Warehouse  |         |   Data Lakehouse  |
+-------------------+         +-------------------+
| Dados estruturados|         | Dados estruturados|
| BI tradicional    |         | + semiestruturados|
| ETL tradicional   |         | + n√£o estruturados|
| Governan√ßa forte  |         | Governan√ßa forte  |
| Performance alta  |         | Performance alta  |
+-------------------+         +-------------------+
```
O data lakehouse combina a flexibilidade e baixo custo do data lake com a governan√ßa, performance e confiabilidade do data warehouse. Enquanto o data warehouse √© √≥timo para dados estruturados e BI, o lakehouse permite trabalhar com dados estruturados, semiestruturados e n√£o estruturados, suportando workloads de BI, ci√™ncia de dados e machine learning em uma √∫nica plataforma.

**Exemplo:**
- Data warehouse: tabelas SQL, ETL tradicional, dados limpos e modelados.
- Data lakehouse: arquivos Parquet/Delta, ingest√£o de dados brutos, processamento incremental, consultas SQL e ML no mesmo ambiente.

**Exerc√≠cio:**
- Liste tr√™s vantagens do lakehouse sobre o data warehouse tradicional.

---

## 1.2 Melhoria da Qualidade de Dados no Lakehouse
O lakehouse melhora a qualidade dos dados em rela√ß√£o ao data lake tradicional por meio de:
- Transa√ß√µes ACID: garante consist√™ncia e integridade dos dados.
- Versionamento: permite consultar vers√µes anteriores dos dados (time travel).
- Schema enforcement: impede grava√ß√£o de dados fora do padr√£o.

**Exemplo pr√°tico:**
```sql
-- Consulta a uma vers√£o anterior de uma tabela Delta
SELECT * FROM vendas VERSION AS OF 2;
```

**Exerc√≠cio:**
- Explique como o schema enforcement pode evitar problemas de qualidade de dados.

---

## 1.3 Tabelas Bronze, Silver e Gold
- **Bronze:** dados brutos, ingest√£o inicial.
- **Silver:** dados limpos, transformados e enriquecidos.
- **Gold:** dados prontos para an√°lise, agregados e otimizados para BI.

```
[Raw Data] -> [Bronze] -> [Silver] -> [Gold] -> [BI/Analytics]
```

**Exemplo de pipeline multi-hop:**
```sql
-- Bronze: ingest√£o
CREATE TABLE bronze AS SELECT * FROM raw_data;
-- Silver: limpeza
CREATE TABLE silver AS SELECT * FROM bronze WHERE status = 'OK';
-- Gold: agrega√ß√£o
CREATE TABLE gold AS SELECT categoria, SUM(valor) FROM silver GROUP BY categoria;
```

**Exerc√≠cio:**
- D√™ um exemplo de workload que consome uma tabela gold.

---

## 1.4 Arquitetura da Plataforma Databricks

```
Usu√°rio
  |
  v
+-------------------+
| Plano de Controle |
| (UI, APIs, Mgmt)  |
+-------------------+
  |
  v
+-------------------+
| Plano de Dados    |
| (Clusters, DBFS)  |
+-------------------+
```
A arquitetura √© dividida em plano de controle (UI, APIs, gerenciamento) e plano de dados (clusters, DBFS, dados do cliente). O plano de controle √© gerenciado pela Databricks; o plano de dados reside na cloud do cliente.

**Desenho simplificado:**
```
[Usu√°rio] -> [Plano de Controle (UI, APIs)] -> [Plano de Dados (Clusters, DBFS, Dados)]
```

**Exerc√≠cio:**
- Explique a diferen√ßa entre plano de controle e plano de dados.

---

## 1.5 Clusters
- **All-purpose cluster:** uso interativo, notebooks, colabora√ß√£o.
- **Jobs cluster:** criado sob demanda para execu√ß√£o de jobs agendados.
- O Databricks Runtime define a vers√£o do Spark e bibliotecas.
- Clusters podem ser filtrados por permiss√µes do usu√°rio.
- Clusters s√£o terminados para liberar recursos; jobs em execu√ß√£o s√£o interrompidos.
- Reiniciar cluster √© √∫til ap√≥s atualiza√ß√£o de bibliotecas ou erro de ambiente.

**Exemplo pr√°tico:**
```python
# Cria√ß√£o de cluster via API (exemplo simplificado)
import requests
requests.post('https://<workspace-url>/api/2.0/clusters/create', json={...})
```

**Exerc√≠cio:**
- Quando √© melhor usar um job cluster em vez de um all-purpose cluster?

---

## 1.6 Notebooks
- Suporte a m√∫ltiplas linguagens: use comandos m√°gicos (%python, %sql, %scala, %r).
- Para rodar um notebook dentro de outro: `%run ./outro_notebook`
- Notebooks podem ser compartilhados via link, permiss√µes ou exporta√ß√£o.

**Exemplo:**
```python
# Alternando linguagens
%python
df = spark.read.csv('/tmp/dados.csv')
%sql
SELECT COUNT(*) FROM tabela_temporaria
```

**Exerc√≠cio:**
- Importe um notebook externo e execute comandos em duas linguagens diferentes.

---

## 1.7 Databricks Repos e Versionamento
- Databricks Repos permite integra√ß√£o com GitHub/GitLab para CI/CD.
- Opera√ß√µes dispon√≠veis: clone, commit, push, pull, branch, merge.
- Limita√ß√µes: versionamento de notebooks nativo n√£o suporta branches, merge ou hist√≥rico detalhado como o Git.

**Exemplo pr√°tico:**
- Adicione um reposit√≥rio Git ao Databricks Repos e fa√ßa um commit de altera√ß√£o em um notebook.

**Exerc√≠cio:**
- Liste duas vantagens de usar Repos em vez do versionamento nativo de notebooks. 