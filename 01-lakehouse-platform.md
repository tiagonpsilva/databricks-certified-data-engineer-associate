# üèùÔ∏è 1. Databricks Lakehouse Platform

## 1.1 Rela√ß√£o entre Data Lakehouse e Data Warehouse

O Data Warehouse tradicional √© focado em dados estruturados, com forte governan√ßa, performance otimizada para BI e processos ETL bem definidos. J√° o Data Lakehouse surge como uma evolu√ß√£o, unificando a flexibilidade do Data Lake (que armazena qualquer tipo de dado) com a governan√ßa e performance do Data Warehouse. Assim, o Lakehouse permite que empresas trabalhem com dados estruturados, semiestruturados e n√£o estruturados, suportando desde relat√≥rios at√© machine learning, tudo em uma √∫nica plataforma.

Exemplo:
- Data warehouse: tabelas SQL, ETL tradicional, dados limpos e modelados.
- Data lakehouse: arquivos Parquet/Delta, ingest√£o de dados brutos, processamento incremental, consultas SQL e ML no mesmo ambiente.

Diagrama comparativo:
```
+---------------------+         +----------------------+
|   Data Warehouse    |         |   Data Lakehouse     |
+---------------------+         +----------------------+
| Dados estruturados  |         | Dados estruturados   |
| BI tradicional      |         | Semiestruturados     |
| ETL tradicional     |         | N√£o estruturados     |
| Governan√ßa forte    |         | Governan√ßa forte     |
| Performance alta    |         | Performance alta     |
+---------------------+         +----------------------+
```

---

## 1.2 Melhoria da Qualidade de Dados no Lakehouse

O Lakehouse resolve problemas cl√°ssicos do Data Lake, como falta de controle de esquema e dificuldade de garantir integridade dos dados. Com transa√ß√µes ACID, versionamento e enforcement de esquema, o Lakehouse garante que os dados estejam sempre consistentes, audit√°veis e prontos para uso anal√≠tico ou operacional.

Exemplo pr√°tico:
```sql
-- Consulta a uma vers√£o anterior de uma tabela Delta
SELECT * FROM vendas VERSION AS OF 2;
```

---

## 1.3 Tabelas Bronze, Silver e Gold

A arquitetura Bronze, Silver e Gold organiza o fluxo de dados em camadas:
- **Bronze:** Dados brutos, ingest√£o inicial, sem tratamento.
- **Silver:** Dados limpos, validados e enriquecidos, prontos para an√°lises intermedi√°rias.
- **Gold:** Dados agregados e otimizados para relat√≥rios, dashboards e consumo por √°reas de neg√≥cio.

Diagrama ASCII:
```
[Raw Data]
    |
    v
+--------+    +--------+    +------+
| Bronze | -> | Silver | -> | Gold |
+--------+    +--------+    +------+
    |             |            |
    v             v            v
 Ingest√£o     Limpeza      Agrega√ß√£o
```

Exemplo de pipeline multi-hop:
```sql
-- Bronze: ingest√£o
CREATE TABLE bronze AS SELECT * FROM raw_data;
-- Silver: limpeza
CREATE TABLE silver AS SELECT * FROM bronze WHERE status = 'OK';
-- Gold: agrega√ß√£o
CREATE TABLE gold AS SELECT categoria, SUM(valor) FROM silver GROUP BY categoria;
```

---

## 1.4 Arquitetura da Plataforma Databricks

A arquitetura do Databricks √© dividida em dois planos:
- **Plano de Controle:** Respons√°vel pela interface, APIs, gerenciamento e autentica√ß√£o. √â gerenciado pela pr√≥pria Databricks.
- **Plano de Dados:** Onde ficam os clusters, arquivos e dados do cliente, hospedados na nuvem do pr√≥prio cliente.

Diagrama ASCII:
```
[Usu√°rio]
    |
    v
+---------------------+
| Plano de Controle   |
| (UI, APIs, Mgmt)    |
+---------------------+
    |
    v
+---------------------+
| Plano de Dados      |
| (Clusters, DBFS)    |
+---------------------+
```

---

## 1.5 Clusters

- **All-purpose cluster:** Ideal para uso interativo, desenvolvimento e colabora√ß√£o em notebooks.
- **Jobs cluster:** Criado sob demanda para execu√ß√£o de jobs agendados, otimizando recursos.
- O Databricks Runtime define o ambiente de execu√ß√£o, incluindo a vers√£o do Spark e bibliotecas.
- Clusters podem ser reiniciados para atualizar depend√™ncias ou corrigir erros de ambiente.
- Clusters podem ser filtrados por permiss√µes do usu√°rio.
- Clusters s√£o terminados para liberar recursos; jobs em execu√ß√£o s√£o interrompidos.

Exemplo pr√°tico:
```python
# Cria√ß√£o de cluster via API (exemplo simplificado)
import requests
requests.post('https://<workspace-url>/api/2.0/clusters/create', json={...})
```

---

## 1.6 Notebooks

Notebooks no Databricks suportam m√∫ltiplas linguagens e facilitam a prototipa√ß√£o, documenta√ß√£o e execu√ß√£o de pipelines de dados. √â poss√≠vel alternar entre Python, SQL, Scala e R usando comandos m√°gicos, al√©m de importar e exportar notebooks facilmente.

Exemplo:
```python
# Alternando linguagens
%python
df = spark.read.csv('/tmp/dados.csv')
%sql
SELECT COUNT(*) FROM tabela_temporaria
```

---

## 1.7 Databricks Repos e Versionamento

O Databricks Repos integra o ambiente com sistemas de controle de vers√£o como GitHub e GitLab, permitindo versionar notebooks, scripts e pipelines. Isso facilita o trabalho colaborativo, CI/CD e o rastreamento de mudan√ßas no c√≥digo.

Exemplo pr√°tico:
- Adicione um reposit√≥rio Git ao Databricks Repos e fa√ßa um commit de altera√ß√£o em um notebook.

--- 