# ğŸï¸ 1. Databricks Lakehouse Platform

## 1.1 RelaÃ§Ã£o entre Data Lakehouse e Data Warehouse

O Data Warehouse tradicional Ã© focado em dados estruturados, com forte governanÃ§a, performance otimizada para BI e processos ETL bem definidos. JÃ¡ o Data Lakehouse surge como uma evoluÃ§Ã£o, unificando a flexibilidade do Data Lake (que armazena qualquer tipo de dado) com a governanÃ§a e performance do Data Warehouse. Assim, o Lakehouse permite que empresas trabalhem com dados estruturados, semiestruturados e nÃ£o estruturados, suportando desde relatÃ³rios atÃ© machine learning, tudo em uma Ãºnica plataforma.

Exemplo:
- Data warehouse: tabelas SQL, ETL tradicional, dados limpos e modelados.
- Data lakehouse: arquivos Parquet/Delta, ingestÃ£o de dados brutos, processamento incremental, consultas SQL e ML no mesmo ambiente.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Warehouse   â”‚         â”‚   Data Lakehouse     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dados estruturados â”‚         â”‚ Dados estruturados   â”‚
â”‚ BI tradicional     â”‚         â”‚ Semiestruturados     â”‚
â”‚ ETL tradicional    â”‚         â”‚ NÃ£o estruturados     â”‚
â”‚ GovernanÃ§a forte   â”‚         â”‚ GovernanÃ§a forte     â”‚
â”‚ Performance alta   â”‚         â”‚ Performance alta     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.2 Melhoria da Qualidade de Dados no Lakehouse

O Lakehouse resolve problemas clÃ¡ssicos do Data Lake, como falta de controle de esquema e dificuldade de garantir integridade dos dados. Com transaÃ§Ãµes ACID, versionamento e enforcement de esquema, o Lakehouse garante que os dados estejam sempre consistentes, auditÃ¡veis e prontos para uso analÃ­tico ou operacional.

Exemplo prÃ¡tico:
```sql
-- Consulta a uma versÃ£o anterior de uma tabela Delta
SELECT * FROM vendas VERSION AS OF 2;
```

---

## 1.3 Tabelas Bronze, Silver e Gold

A arquitetura Bronze, Silver e Gold organiza o fluxo de dados em camadas:
- **Bronze:** Dados brutos, ingestÃ£o inicial, sem tratamento.
- **Silver:** Dados limpos, validados e enriquecidos, prontos para anÃ¡lises intermediÃ¡rias.
- **Gold:** Dados agregados e otimizados para relatÃ³rios, dashboards e consumo por Ã¡reas de negÃ³cio.

```
        [Raw Data]
             |
             v
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”
   â”‚Bronze â”‚-->|Silver â”‚-->|Gold â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜
       |           |           |
       v           v           v
   IngestÃ£o    Limpeza    AgregaÃ§Ã£o
```

Exemplo de pipeline multi-hop:
```sql
-- Bronze: ingestÃ£o
CREATE TABLE bronze AS SELECT * FROM raw_data;
-- Silver: limpeza
CREATE TABLE silver AS SELECT * FROM bronze WHERE status = 'OK';
-- Gold: agregaÃ§Ã£o
CREATE TABLE gold AS SELECT categoria, SUM(valor) FROM silver GROUP BY categoria;
```

---

## 1.4 Arquitetura da Plataforma Databricks

A arquitetura do Databricks Ã© dividida em dois planos:
- **Plano de Controle:** ResponsÃ¡vel pela interface, APIs, gerenciamento e autenticaÃ§Ã£o. Ã‰ gerenciado pela prÃ³pria Databricks.
- **Plano de Dados:** Onde ficam os clusters, arquivos e dados do cliente, hospedados na nuvem do prÃ³prio cliente.

```
   [UsuÃ¡rio]
       |
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Plano de Controle     â”‚
â”‚ (UI, APIs, Mgmt)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       |
       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Plano de Dados        â”‚
â”‚ (Clusters, DBFS)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1.5 Clusters

- **All-purpose cluster:** Ideal para uso interativo, desenvolvimento e colaboraÃ§Ã£o em notebooks.
- **Jobs cluster:** Criado sob demanda para execuÃ§Ã£o de jobs agendados, otimizando recursos.
- O Databricks Runtime define o ambiente de execuÃ§Ã£o, incluindo a versÃ£o do Spark e bibliotecas.
- Clusters podem ser reiniciados para atualizar dependÃªncias ou corrigir erros de ambiente.
- Clusters podem ser filtrados por permissÃµes do usuÃ¡rio.
- Clusters sÃ£o terminados para liberar recursos; jobs em execuÃ§Ã£o sÃ£o interrompidos.

Exemplo prÃ¡tico:
```python
# CriaÃ§Ã£o de cluster via API (exemplo simplificado)
import requests
requests.post('https://<workspace-url>/api/2.0/clusters/create', json={...})
```

---

## 1.6 Notebooks

Notebooks no Databricks suportam mÃºltiplas linguagens e facilitam a prototipaÃ§Ã£o, documentaÃ§Ã£o e execuÃ§Ã£o de pipelines de dados. Ã‰ possÃ­vel alternar entre Python, SQL, Scala e R usando comandos mÃ¡gicos, alÃ©m de importar e exportar notebooks facilmente.

Exemplo:
```python
# Alternando linguagens
%python
df = spark.read.csv('/tmp/dados.csv')
%sql
SELECT COUNT(*) FROM tabela_temporaria
```

---

## 1.7 Databricks Repos e Versionamento

O Databricks Repos integra o ambiente com sistemas de controle de versÃ£o como GitHub e GitLab, permitindo versionar notebooks, scripts e pipelines. Isso facilita o trabalho colaborativo, CI/CD e o rastreamento de mudanÃ§as no cÃ³digo.

Exemplo prÃ¡tico:
- Adicione um repositÃ³rio Git ao Databricks Repos e faÃ§a um commit de alteraÃ§Ã£o em um notebook.

--- 